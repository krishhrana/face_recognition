{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyrebase\n",
    "import cv2\n",
    "import urllib\n",
    "import numpy as np\n",
    "import dlib\n",
    "from TinyFacesDetector import TinyFacesDetector\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyStuffTracker(object):\n",
    "    config={\n",
    "    \"apiKey\": \"AIzaSyAK8nmjG1jxZ0plg9jr5je5vmb3WLVOc-s\",\n",
    "    \"authDomain\": \"trial-a6e1b.firebaseapp.com\",\n",
    "    \"databaseURL\": \"https://trial-a6e1b.firebaseio.com\",\n",
    "    \"projectId\": \"trial-a6e1b\",\n",
    "    \"storageBucket\": \"trial-a6e1b.appspot.com\",\n",
    "    \"messagingSenderId\": \"290957423485\",\n",
    "    \"appId\": \"1:290957423485:web:fffc0d605a278696929214\",\n",
    "    \"serviceAccount\": \"trial-a6e1b-firebase-adminsdk-6wv5o-bca0d33be1.json\"\n",
    "}\n",
    "    firebase=pyrebase.initialize_app(config)\n",
    "    database=firebase.database()\n",
    "    storage=firebase.storage()\n",
    "    face_detector=TinyFacesDetector(\"weights.pkl\",use_gpu=True)\n",
    "    model=load_model('DeepMaskFacev10.h5', compile=False)\n",
    "    my_stuff: list([dict]) = None # In my example my data is a list of some dictionaries\n",
    "    @property\n",
    "    def is_ready(self) -> bool:\n",
    "        return self.my_stuff is not None\n",
    "    \n",
    "    def isBlurry(self, img):\n",
    "        img=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        blur=cv2.Laplacian(img, cv2.CV_64F).var()\n",
    "        if blur<100:\n",
    "            return True, blur\n",
    "        else:\n",
    "            return False, blur\n",
    "\n",
    "    def stream_handler(self, message):\n",
    "        image_list=[]\n",
    "        print(\"Got some update from the Firebase\")\n",
    "        if message[\"event\"] in (\"put\", \"patch\"):\n",
    "            print(\"Something changed\")\n",
    "            print(message[\"path\"])\n",
    "            if message[\"path\"]=='/':\n",
    "                print(\"Seems like a fresh data or everything have changed, just grab it!\")\n",
    "                self.my_stuff: list([dict]) = message[\"data\"]\n",
    "            else:\n",
    "                print(\"Something updated somewhere, I dont't care I just want the latest snapshot of my stuff\")\n",
    "                # Just get whole-data of my stuff and list (second) item of the pyres (that I expect to be a dict)\n",
    "                self.my_stuff: list([dict]) = list(it.item[1] for it in self.database.child(\"Face Data\").get().pyres)\n",
    "            for i in self.my_stuff:\n",
    "                filename=self.my_stuff[i]['id']+'.jpg'\n",
    "                urls=self.storage.child('faces/'+filename).get_url(None)\n",
    "                resp = urllib.request.urlopen(urls)\n",
    "                image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
    "                image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "                check, blur=self.isBlurry(image)\n",
    "                print('BLUR CHECK')\n",
    "                if check is False:\n",
    "                    rects=self.face_detector.detect(image,nms_thresh=0.1,prob_thresh=0.9,min_conf=0.9)\n",
    "                    if len(rects)!=0: \n",
    "                        image=cv2.resize(image, (112,112))\n",
    "                        image=image/255\n",
    "                        image=np.array(image).reshape(-1,112,112,3)\n",
    "                        image_list.append(image)\n",
    "            print('INFERENCING')\n",
    "            pred=self.model.predict(image_list)\n",
    "            for i in range(len(pred)-1):\n",
    "                for j in range(i+1, len(pred)):\n",
    "                    dist= np.linalg.norm(pred[i]-pred[j])\n",
    "                    if dist<0.685:\n",
    "                        print(i, j)\n",
    "    \n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        \"\"\"Start tracking my stuff changes in Firebase\"\"\"\n",
    "        super().__init__()\n",
    "        self.database.child(\"Face Data\").stream(self.stream_handler)\n",
    "\n",
    "\n",
    "tracker = MyStuffTracker()\n",
    "\n",
    "while not tracker.is_ready:\n",
    "    pass  # Just wait until the first snapshot of my stuff will be ready\n",
    "\n",
    "print(f\"My stuff is: Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\n",
    "    \"apiKey\": \"AIzaSyAK8nmjG1jxZ0plg9jr5je5vmb3WLVOc-s\",\n",
    "    \"authDomain\": \"trial-a6e1b.firebaseapp.com\",\n",
    "    \"databaseURL\": \"https://trial-a6e1b.firebaseio.com\",\n",
    "    \"projectId\": \"trial-a6e1b\",\n",
    "    \"storageBucket\": \"trial-a6e1b.appspot.com\",\n",
    "    \"messagingSenderId\": \"290957423485\",\n",
    "    \"appId\": \"1:290957423485:web:fffc0d605a278696929214\",\n",
    "    \"serviceAccount\": \"trial-a6e1b-firebase-adminsdk-6wv5o-bca0d33be1.json\"\n",
    "}\n",
    "firebase=pyrebase.initialize_app(config)\n",
    "database=firebase.database()\n",
    "storage=firebase.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Streamer:\n",
    "    \n",
    "    def __init__(self, database, storage, face_detector, img_list):\n",
    "        self.face_detector=face_detector\n",
    "        self.database=database\n",
    "        self.storage=storage\n",
    "        self.img_list=img_list\n",
    "    \n",
    "    def isBlurry(self, img):\n",
    "        img=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        blur=cv2.Laplacian(img, cv2.CV_64F).var()\n",
    "        if blur<100:\n",
    "            return True, blur\n",
    "        else:\n",
    "            return False, blur\n",
    "    \n",
    "    def cleanDatabase(self, ids):\n",
    "        name=self.database.child('Face Data').get()\n",
    "        filename=ids+'.jpg'\n",
    "        urls=self.storage.child('faces/'+filename).get_url(None)\n",
    "        resp = urllib.request.urlopen(urls)\n",
    "        image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
    "        image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "        check, blur=self.isBlurry(image)\n",
    "        if check is False:\n",
    "            rects=self.face_detector.detect(image,nms_thresh=0.1,prob_thresh=0.9,min_conf=0.9)\n",
    "            if len(rects)!=0: \n",
    "                image=cv2.resize(image, (112,112))\n",
    "                image=image/255\n",
    "                image=np.array(image).reshape(-1,112,112,3)\n",
    "        return image\n",
    "     \n",
    "    \n",
    "    def getSimilarFaces(self, face_recognizer, imageList):\n",
    "        pred=self.face_recognizer.predict(imageList)\n",
    "        similar_faces=[]\n",
    "        for i in range(len(pred)-1):\n",
    "            for j in range(i+1, len(pred)):\n",
    "                dist= np.linalg.norm(pred[i]-pred[j])\n",
    "                if dist<0.685:\n",
    "                    similar_faces.append([i, j])\n",
    "        return similar_faces\n",
    "    \n",
    "    def stream_handler(self, message):\n",
    "        print(message[\"event\"]) # put\n",
    "        print(message[\"path\"]) # /-K7yGTTEp7O549EzTYtI\n",
    "        data=message['data']\n",
    "        for i in data:\n",
    "            new_id=data[i]['id']\n",
    "            faces=self.cleanDatabase(new_id)\n",
    "            self.img_list.append(faces)\n",
    "            print(len(self.img_list))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list=[]\n",
    "r1=Streamer(database, storage, tiny_faces_detector,  image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database.child('Face Data').stream(r1.stream_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanDatabase(database, storage, face_detector):\n",
    "    name=database.child('Face Data').get()\n",
    "    image_list=[]\n",
    "    names=[]\n",
    "    for i in name.each():\n",
    "        filename=i.key()+'.jpg'\n",
    "        urls=storage.child('faces/'+filename).get_url(None)\n",
    "        resp = urllib.request.urlopen(urls)\n",
    "        image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
    "        image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "        check, blur=isBlurry(image)\n",
    "        if check is False:\n",
    "            with graph.as_default():\n",
    "                rects=face_detector.detect(image,nms_thresh=0.1,prob_thresh=0.9,min_conf=0.9)\n",
    "                if len(rects)!=0: \n",
    "                    image=cv2.resize(image, (112,112))\n",
    "                    image_list.append(image)\n",
    "                    #print(filename, check, blur)\n",
    "                names.append(filename)\n",
    "    return image_list, names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSimilarFaces(recognition_model, imageList):\n",
    "    with graph.as_default():\n",
    "        pred=model.predict(imageList)\n",
    "    similar_faces=[]\n",
    "    for i in range(len(pred)-1):\n",
    "        for j in range(i+1, len(pred)):\n",
    "            dist= np.linalg.norm(pred[i]-pred[j])\n",
    "            if dist<0.685:\n",
    "                similar_faces.append([i, j])\n",
    "    return similar_faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces, name_list=cleanDatabase(database, storage, tiny_faces_detector)\n",
    "processed_faces=np.array(faces).reshape(-1,112,112,3)\n",
    "processed_faces=processed_faces/255\n",
    "similar_face_list=getSimilarFaces(model, processed_faces)\n",
    "for i in similar_face_list:\n",
    "    img1,img2=faces[i[0]], faces[i[1]]\n",
    "    c1,b1=isBlurry(img1)\n",
    "    c2,b2=isBlurry(img2)\n",
    "    if b1<b2:\n",
    "        print(name_list[i[0]]+' Deleted!'')\n",
    "    else:\n",
    "        print(name_list[i[1]]+' Deleted!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances=[]\n",
    "for i in range(len(pred)-1):\n",
    "    for j in range(i+1, len(pred)):\n",
    "        dist= np.linalg.norm(pred[i]-pred[j])\n",
    "        if dist<0.685:\n",
    "            distances.append([i, j])\n",
    "print(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(img1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_handler(message):\n",
    "    new_ids=[]\n",
    "    print(message[\"event\"]) # put\n",
    "    print(message[\"path\"]) # /-K7yGTTEp7O549EzTYtI\n",
    "    data=message['data']\n",
    "    for i in data:\n",
    "        print(data[i]['id'])        \n",
    "my_stream = database.child('Face Data').stream(stream_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1.shape\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0824 16:57:59.407405 4683072960 deprecation.py:323] From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import firebase_admin\n",
    "from firebase_admin import credentials\n",
    "from firebase_admin import db\n",
    "from firebase_admin import storage\n",
    "import cv2\n",
    "import urllib\n",
    "import numpy as np\n",
    "import dlib\n",
    "from TinyFacesDetector import TinyFacesDetector\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cred=credentials.Certificate('trial-a6e1b-firebase-adminsdk-6wv5o-bca0d33be1.json')\n",
    "firebase_admin.initialize_app(cred, {\n",
    "    \"databaseURL\":\"https://trial-a6e1b.firebaseio.com/Face%20Data\",\n",
    "    \"storageBucket\": \"trial-a6e1b.appspot.com\",\n",
    "    \"projectId\": \"trial-a6e1b\",\n",
    "    \"serviceAccount\": \"trial-a6e1b-firebase-adminsdk-6wv5o-bca0d33be1.json\"\n",
    "})\n",
    "global graph\n",
    "graph = tf.compat.v1.get_default_graph()\n",
    "ref=db.reference('Face Data')\n",
    "bucket = storage.bucket()\n",
    "tiny_faces_detector=TinyFacesDetector(\"weights.pkl\",use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isBlurry(img):\n",
    "    img=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    blur=cv2.Laplacian(img, cv2.CV_64F).var()\n",
    "    if blur<100:\n",
    "        return True, blur\n",
    "    else:\n",
    "        return False, blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanDatabase(ids):\n",
    "    imageList=[]\n",
    "    names=[]\n",
    "    for i in ids:\n",
    "        filename=i+'.jpg'\n",
    "        blob = bucket.blob(\"faces/\"+filename)\n",
    "        urls=blob.generate_signed_url(datetime.timedelta(seconds=300), method='GET')\n",
    "        #print(urls)\n",
    "        resp = urllib.request.urlopen(urls)\n",
    "        image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
    "        image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "        check, blur=isBlurry(image)\n",
    "        if check is False:\n",
    "            with graph.as_default():\n",
    "                rects=tiny_faces_detector.detect(image,nms_thresh=0.1,prob_thresh=0.9,min_conf=0.9)\n",
    "            if len(rects)!=0: \n",
    "                image=cv2.resize(image, (112,112))\n",
    "                image=image/255\n",
    "                image=np.array(image).reshape(-1,112,112,3)\n",
    "                imageList.append(image)\n",
    "                names.append(filename)\n",
    "    return imageList, names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEmbeddings(imageList):\n",
    "    model=load_model('DeepMaskFacev10.h5', compile=False)\n",
    "    pred=model.predict(imageList)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deleteSimilarFaces(prediction_list, reference_list, name_list):\n",
    "    cleanup_list=reference_list\n",
    "    similar_faces=[]\n",
    "    for i in range(len(prediction_list)):\n",
    "        for j in range(len(reference_list)):\n",
    "            dist= np.linalg.norm(prediction_list[i]-reference_list[j])\n",
    "            print(dist)\n",
    "            if dist!=0.0:\n",
    "                if dist<0.685:\n",
    "                    print(name_list[i], name_list[j])\n",
    "                    blob = bucket.blob('faces/'+name_list[i])\n",
    "                    blob.delete()  \n",
    "                    print(name_list[i]+'DELETED!')\n",
    "                    del name_list[i]\n",
    "                    cleanup_list = np.delete(cleanup_list, i)\n",
    "    return name_list, cleanup_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\n",
      "ID:0\n",
      "ID:1\n",
      "ID:2\n",
      "ID:15\n",
      "ID:20\n",
      "ID:21\n",
      "ID:23\n",
      "ID:24\n",
      "ID:26\n",
      "ID:31\n",
      "ID:33\n",
      "ID:34\n",
      "ID:38\n",
      "(10, 112, 112, 3)\n",
      "0.0\n",
      "1.2883322\n",
      "1.5341786\n",
      "1.2611012\n",
      "1.4772713\n",
      "1.51352\n",
      "1.4263426\n",
      "1.5516754\n",
      "1.3705862\n",
      "1.3334845\n",
      "1.2883322\n",
      "0.0\n",
      "1.5814459\n",
      "1.2891142\n",
      "1.2405472\n",
      "1.4438819\n",
      "1.4637365\n",
      "1.4185954\n",
      "1.4300865\n",
      "1.3785691\n",
      "1.5341786\n",
      "1.5814459\n",
      "0.0\n",
      "1.4172193\n",
      "1.4639843\n",
      "1.4257482\n",
      "1.5903492\n",
      "1.4534167\n",
      "1.4821795\n",
      "1.5181111\n",
      "1.2611012\n",
      "1.2891142\n",
      "1.4172193\n",
      "0.0\n",
      "1.3981897\n",
      "1.3555696\n",
      "1.5251808\n",
      "1.3660499\n",
      "1.4018229\n",
      "1.2549126\n",
      "1.4772713\n",
      "1.2405472\n",
      "1.4639843\n",
      "1.3981897\n",
      "0.0\n",
      "1.4875665\n",
      "1.4482341\n",
      "1.4588368\n",
      "1.3439732\n",
      "1.3737315\n",
      "1.51352\n",
      "1.4438819\n",
      "1.4257482\n",
      "1.3555696\n",
      "1.4875665\n",
      "0.0\n",
      "1.4396768\n",
      "0.25575686\n",
      "24.jpg 33.jpg\n",
      "1.516684\n",
      "1.3573794\n",
      "1.4263426\n",
      "1.4637365\n",
      "1.5903492\n",
      "1.5251808\n",
      "1.4482341\n",
      "1.4396768\n",
      "0.0\n",
      "1.4345622\n",
      "1.3171455\n",
      "1.3712214\n",
      "1.5516754\n",
      "1.4185954\n",
      "1.4534167\n",
      "1.3660499\n",
      "1.4588368\n",
      "0.25575686\n",
      "34.jpg 31.jpg\n",
      "1.4345622\n",
      "0.0\n",
      "1.4246385\n",
      "1.2852637\n",
      "1.3705862\n",
      "1.4300865\n",
      "1.4821795\n",
      "1.4018229\n",
      "1.3439732\n",
      "1.516684\n",
      "1.3171455\n",
      "1.4246385\n",
      "0.0\n",
      "1.4023788\n",
      "1.3334845\n",
      "1.3785691\n",
      "1.5181111\n",
      "1.2549126\n",
      "1.3737315\n",
      "1.3573794\n",
      "1.3712214\n",
      "1.2852637\n",
      "1.4023788\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "new_embeds_list=[]\n",
    "clean_names=[]\n",
    "def listen(event):\n",
    "    id_list=[]\n",
    "    new_id=[]\n",
    "    print(event.path)\n",
    "    if event.path=='/':\n",
    "        for i in event.data:\n",
    "            print('ID:'+ i)\n",
    "            id_list.append(i)\n",
    "        faces, names=cleanDatabase(id_list)\n",
    "        faces=np.array(faces).reshape(-1,112,112,3)\n",
    "        print(faces.shape)\n",
    "        embeddings=getEmbeddings(faces)\n",
    "        clean_names, new_embeds_list=deleteSimilarFaces(embeddings, embeddings, names)\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        for i in event.data:\n",
    "            new_id_list.append(event.data[i])\n",
    "        \n",
    "        new_faces, new_names=cleanDatabase(new_id_list)\n",
    "        new_embeddings=getEmbeddings(new_faces)\n",
    "        new_clean_names, new_cleanup_list=deleteSimilarFaces(new_embeddings, \n",
    "                                                             new_embeds_list, new_names)\n",
    "        \n",
    "        np.concatenate(new_embeds_list, new_cleanup_list)\n",
    "    \n",
    "            \n",
    "listner=ref.listen(listen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

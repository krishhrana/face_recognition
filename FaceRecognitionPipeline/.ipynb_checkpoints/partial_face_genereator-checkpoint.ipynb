{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0716 12:49:58.597231 4561860032 deprecation.py:323] From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import dlib\n",
    "import imutils\n",
    "import os\n",
    "import cv2\n",
    "from TinyFacesDetector import TinyFacesDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pkl=\"weights.pkl\"\n",
    "tiny_faces_detector = TinyFacesDetector(model_pkl,use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape_to_np(shape, dtype=\"int\"):\n",
    "\t# initialize the list of (x, y)-coordinates\n",
    "    coords = np.zeros((68, 2), dtype=dtype)\n",
    "\t# loop over the 68 facial landmarks and convert them\n",
    "\t# to a 2-tuple of (x, y)-coordinates\n",
    "    for i in range(0, 68):\n",
    "        coords[i] = (shape.part(i).x, shape.part(i).y)\n",
    "\t# return the list of (x, y)-coordinates\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shape(d_rects, gray):\n",
    "    for ret in d_rects:\n",
    "        # We will determine the facial landmarks for the face region, then \n",
    "        # can convert the facial landmark (x, y)-coordinates to a NumPy array \n",
    "        shape = predictor(gray, box=ret)\n",
    "    shape=shape_to_np(shape)\n",
    "    return shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dlib_rectangle(d_rects):\n",
    "    for d in d_rects:\n",
    "        x,y,w,h = d[0],d[1],d[2],d[3]\n",
    "    face_rects=[dlib.rectangle(x, y, w, h)]\n",
    "    return face_rects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_data(directory, output_path):\n",
    "    for subdir in os.listdir(directory):\n",
    "        path=os.path.join(directory, subdir)\n",
    "        print(path)\n",
    "        try:\n",
    "            for img in os.listdir(path):\n",
    "                try:\n",
    "                    image_array=cv2.imread(os.path.join(path, img))\n",
    "                    image_array=cv2.resize(image_array, (160,160))\n",
    "                    gray = cv2.cvtColor(image_array, cv2.COLOR_BGR2GRAY)\n",
    "                    d_rects = tiny_faces_detector.detect(gray,nms_thresh=0.1,prob_thresh=0.5,min_conf=0.9)\n",
    "                    for d in d_rects:\n",
    "                        x,y,w,h = d[0],d[1],d[2],d[3]\n",
    "                    face_rects=[dlib.rectangle(x, y, w, h)]\n",
    "                    for ret in face_rects:\n",
    "                        shape = predictor(gray, box=ret)\n",
    "                        shape=shape_to_np(shape)\n",
    "                    half_face=image_array[shape[19][1]:shape[29][1], shape[0][0]:shape[16][0]]\n",
    "                    o_p=os.path.join(output_path, subdir)\n",
    "                    op=os.path.join(o_p, img)\n",
    "                    print(o_p)\n",
    "                    cv2.imwrite(os.path.join(output_path, subdir, img), half_face)\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "        except NotADirectoryError as d:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/krishrana/AjnaLens/Resources/Models/FaceDetectionPipeline/output/.DS_Store\n",
      "/Users/krishrana/AjnaLens/Resources/Models/FaceDetectionPipeline/output/Krish\n"
     ]
    }
   ],
   "source": [
    "training_data=list()\n",
    "output_path='/Users/krishrana/AjnaLens/Resources/Models/FaceDetectionPipeline/partialFaces'\n",
    "get_training_data('/Users/krishrana/AjnaLens/Resources/Models/FaceDetectionPipeline/output', output_path)\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(training_data[-73][0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output_path+'/'+str('krish'), img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

# -*- coding: utf-8 -*-
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
import os
import tensorflow as tf
from FaceDetection.tiny_face_model import Model
import numpy as np
import cv2
import pickle
import tensorflow.compat.v1 as tf
tf.disable_v2_behavior()
import pylab as pl
import time

from scipy.special import expit
import dlib

class TinyFacesDetector():
    def __init__(self,model_file,use_gpu=True):
        if not use_gpu:
            os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"   # see issue #152
            os.environ["CUDA_VISIBLE_DEVICES"] = ""
        self.model_file=model_file
        self.model = Model(self.model_file)
        # Load an average image and clusters(reference boxes of templates).
        with open(self.model_file, "rb") as f:
            _, mat_params_dict = pickle.load(f,encoding='latin1')
        self.MAX_INPUT_DIM = 5000.0
        self.average_image = self.model.get_data_by_key("average_image")
        clusters = self.model.get_data_by_key("clusters")
        self.clusters=clusters
        self.clusters_h = clusters[:, 3] - clusters[:, 1] + 1
        self.clusters_w = clusters[:, 2] - clusters[:, 0] + 1
        self.normal_idx = np.where(clusters[:, 4] == 1)
        self.init_ok=False
        self.x = tf.placeholder(tf.float32, [1, None, None, 3])  # n, h, w, c
        self.score_final = self.model.tiny_face(self.x)
        self.Session=tf.Session()
        self.Session.run(tf.global_variables_initializer())


    def detect(self, filename, prob_thresh=0.5, nms_thresh=0.1,min_conf=0.9):
        """Detect faces in images.
        Args:
          prob_thresh:
              The threshold of detection confidence.
          nms_thresh:
              The overlap threshold of non maximum suppression
          weight_file_path:
              A pretrained weight file in the pickle format
              generated by matconvnet_hr101_to_tf.py.
        Returns:
          List of dlib rectangles.
        """

        #raw_img = cv2.imread(filename)
        raw_img = filename
        raw_img = cv2.cvtColor(raw_img, cv2.COLOR_BGR2RGB)
        raw_img_f = raw_img.astype(np.float32)

        def _calc_scales():
            raw_h, raw_w = raw_img.shape[0], raw_img.shape[1]
            min_scale = min(np.floor(np.log2(np.max(self.clusters_w[self.normal_idx] / raw_w))),
                            np.floor(np.log2(np.max(self.clusters_h[self.normal_idx] / raw_h))))
            max_scale = min(1.0, -np.log2(max(raw_h, raw_w) / self.MAX_INPUT_DIM))
            scales_down = np.arange(min_scale, 0, 1.)
            scales_up = np.arange(0.5, max_scale, 0.5)
            scales_pow = np.hstack((scales_down, scales_up))
            scales = np.power(2.0, scales_pow)
            return scales

        scales = _calc_scales()
        start = time.time()

        # initialize output
        bboxes = np.empty(shape=(0, 5))

        # process input at different scales
        for s in scales:
            img = cv2.resize(raw_img_f, (0, 0), fx=s, fy=s, interpolation=cv2.INTER_LINEAR)
            img = img - self.average_image
            img = img[np.newaxis, :]

            # we don't run every template on every scale ids of templates to ignore
            tids = list(range(4, 12)) + ([] if s <= 1.0 else list(range(18, 25)))
            ignoredTids = list(set(range(0, self.clusters.shape[0])) - set(tids))

            # run through the net
            score_final_tf = self.Session.run(self.score_final, feed_dict={self.x: img})

            # collect scores
            score_cls_tf, score_reg_tf = score_final_tf[:, :, :, :25], score_final_tf[:, :, :, 25:125]
            prob_cls_tf = expit(score_cls_tf)
            prob_cls_tf[0, :, :, ignoredTids] = 0.0

            def _calc_bounding_boxes():
                # threshold for detection
                _, fy, fx, fc = np.where(prob_cls_tf > prob_thresh)

                # interpret heatmap into bounding boxes
                cy = fy * 8 - 1
                cx = fx * 8 - 1
                ch = self.clusters[fc, 3] - self.clusters[fc, 1] + 1
                cw = self.clusters[fc, 2] - self.clusters[fc, 0] + 1

                # extract bounding box refinement
                Nt = self.clusters.shape[0]
                tx = score_reg_tf[0, :, :, 0:Nt]
                ty = score_reg_tf[0, :, :, Nt:2 * Nt]
                tw = score_reg_tf[0, :, :, 2 * Nt:3 * Nt]
                th = score_reg_tf[0, :, :, 3 * Nt:4 * Nt]

                # refine bounding boxes
                dcx = cw * tx[fy, fx, fc]
                dcy = ch * ty[fy, fx, fc]
                rcx = cx + dcx
                rcy = cy + dcy
                rcw = cw * np.exp(tw[fy, fx, fc])
                rch = ch * np.exp(th[fy, fx, fc])

                scores = score_cls_tf[0, fy, fx, fc]
                tmp_bboxes = np.vstack((rcx - rcw / 2, rcy - rch / 2, rcx + rcw / 2, rcy + rch / 2))
                tmp_bboxes = np.vstack((tmp_bboxes / s, scores))
                tmp_bboxes = tmp_bboxes.transpose()
                return tmp_bboxes

            tmp_bboxes = _calc_bounding_boxes()
            bboxes = np.vstack((bboxes, tmp_bboxes))  # <class 'tuple'>: (5265, 5)


        # non maximum suppression
        refind_idx = tf.image.non_max_suppression(tf.convert_to_tensor(bboxes[:, :4], dtype=tf.float32),
                                                  tf.convert_to_tensor(bboxes[:, 4], dtype=tf.float32),
                                                  max_output_size=bboxes.shape[0], iou_threshold=nms_thresh)
        refind_idx = self.Session.run(refind_idx)
        refined_bboxes = bboxes[refind_idx]
        boxes = []
        for r in refined_bboxes:
            # print (face_index)
            _r = [int(x) for x in r[:4]]
            _score = expit(r[4])
            if _score > min_conf:
                det = (int(_r[0]), int(_r[1]), int(_r[2]), int(_r[3]))
                boxes.append(det)

        return boxes
